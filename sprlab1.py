# -*- coding: utf-8 -*-
"""SPRLab1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f0faC89xAQQt9qNQd9bDWstYtKL6Rz4r
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
from scipy import signal

# -------------------------
# (a) Load original speech signal
# -------------------------
fs, speech = wavfile.read("/content/LJ001-0001.wav")
speech = speech.astype(float) / np.max(np.abs(speech))  # Normalize

time = np.arange(len(speech)) / fs

plt.figure(figsize=(10, 4))
plt.plot(time, speech)
plt.title("Original Speech Signal (Time Domain)")
plt.xlabel("Time [s]")
plt.ylabel("Amplitude")
plt.grid(True)
plt.show()

# -------------------------
# (b) Sample at different rates
# -------------------------
sampling_rates = [8000, 16000, 44100]
sampled_signals = {}

for sr in sampling_rates:
    # Resample
    num_samples = int(len(speech) * sr / fs)
    sampled = signal.resample(speech, num_samples)
    sampled_signals[sr] = sampled

    # Plot
    t = np.arange(len(sampled)) / sr
    plt.figure(figsize=(10, 3))
    plt.plot(t, sampled)
    plt.title(f"Speech Signal Sampled at {sr} Hz")
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.grid(True)
    plt.show()

# -------------------------
# (d) Reconstruction
# -------------------------
def zero_order_hold(x, sr, target_fs, duration):
    """Reconstruct using Zero-Order Hold (Nearest Neighbor)"""
    t_new = np.arange(0, duration, 1/target_fs)
    t_old = np.arange(len(x)) / sr
    return np.interp(t_new, t_old, x, left=0, right=0)

def linear_interp(x, sr, target_fs, duration):
    """Reconstruct using Linear Interpolation"""
    t_new = np.arange(0, duration, 1/target_fs)
    t_old = np.arange(len(x)) / sr
    return np.interp(t_new, t_old, x)

mse_results = {}

for sr, sig in sampled_signals.items():
    duration = len(sig) / sr

    # Zero-order hold
    zoh = zero_order_hold(sig, sr, fs, duration)
    zoh = zoh[:len(speech)]  # match lengths
    mse_zoh = np.mean((speech[:len(zoh)] - zoh)**2)

    # Linear interpolation
    lin = linear_interp(sig, sr, fs, duration)
    lin = lin[:len(speech)]
    mse_lin = np.mean((speech[:len(lin)] - lin)**2)

    mse_results[sr] = (mse_zoh, mse_lin)

    # Plot
    plt.figure(figsize=(10, 3))
    plt.plot(time[:len(zoh)], speech[:len(zoh)], label="Original")
    plt.plot(time[:len(zoh)], zoh, '--', label="ZOH Reconstruction")
    plt.plot(time[:len(lin)], lin, ':', label="Linear Reconstruction")
    plt.title(f"Reconstruction at {sr} Hz")
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.legend()
    plt.grid(True)
    plt.show()

# Print MSE
for sr, (mse_zoh, mse_lin) in mse_results.items():
    print(f"Sampling Rate: {sr} Hz")
    print(f"  MSE (Zero-Order Hold): {mse_zoh:.6f}")
    print(f"  MSE (Linear Interpolation): {mse_lin:.6f}\n")

# -------------------------
# (a) Source-filter model
# -------------------------

# Source: Voiced speech = glottal pulse train
fs = 16000
duration = 0.5
f0 = 120  # pitch frequency (Hz)

t = np.arange(0, duration, 1/fs)
source_voiced = signal.square(2*np.pi*f0*t)  # periodic pulse train

# Unvoiced: white noise
source_unvoiced = np.random.randn(len(t))

# Vocal tract filter (formants using poles)
formants = [500, 1500, 2500]  # example formant frequencies
bw = 50  # bandwidth
b, a = signal.iirpeak(formants[0]/(fs/2), bw/fs)  # single formant filter
for f in formants[1:]:
    b_f, a_f = signal.iirpeak(f/(fs/2), bw/fs)
    b = np.convolve(b, b_f)
    a = np.convolve(a, a_f)

    # Apply filter
speech_voiced = signal.lfilter(b, a, source_voiced)
speech_unvoiced = signal.lfilter(b, a, source_unvoiced)

plt.figure(figsize=(10, 4))
plt.plot(t[:1000], speech_voiced[:1000])
plt.title("Synthetic Voiced Speech Signal (Source-Filter Model)")
plt.xlabel("Time [s]")
plt.ylabel("Amplitude")
plt.grid(True)
plt.show()

# -------------------------
# (c) Sample at different rates and reconstruct
# -------------------------
sampling_rates = [8000, 16000, 44100]
mse_results_sf = {}

for sr in sampling_rates:
    # Resample
    num_samples = int(len(speech_voiced) * sr / fs)
    sampled = signal.resample(speech_voiced, num_samples)

    # Reconstruction
    lin = linear_interp(sampled, sr, fs, duration)
    lin = lin[:len(speech_voiced)]

    mse = np.mean((speech_voiced[:len(lin)] - lin)**2)
    mse_results_sf[sr] = mse

    plt.figure(figsize=(10, 3))
    plt.plot(t[:2000], speech_voiced[:2000], label="Original")
    plt.plot(t[:2000], lin[:2000], '--', label=f"Reconstructed @ {sr} Hz")
    plt.title(f"Source-Filter Speech Reconstruction at {sr} Hz")
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.legend()
    plt.grid(True)
    plt.show()

# Print MSE
for sr, mse in mse_results_sf.items():
    print(f"Source-Filter Model - Sampling Rate: {sr} Hz, MSE: {mse:.6f}")

