# -*- coding: utf-8 -*-
"""SPR_Lab4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vFB_ILcwRXrowYcZyQm1lT3lXdfXhUO9
"""

pip install numpy scipy matplotlib pandas

# lpc_lab_demo.py
# Run with: python lpc_lab_demo.py
# Requires: numpy, scipy, matplotlib, pandas

import numpy as np
from scipy import signal
from scipy.io import wavfile
import matplotlib.pyplot as plt
import pandas as pd
import os

# ---------------------------
# PARAMETERS
# ---------------------------
fs = 16000            # sampling rate (Hz)
duration = 3.0        # seconds of audio
t = np.linspace(0, duration, int(fs*duration), endpoint=False)

# ---------------------------
# 1) SYNTHESIZE A VOICED VOWEL (demo)
# ---------------------------
# We'll synthesize an /a/ vowel using a simple source-filter model so you can test immediately.
f0 = 120.0                         # fundamental (Hz)
harmonics = np.arange(1, 40)       # few harmonics
source = np.sum([(1.0/h) * np.sin(2*np.pi*f0*h*t) for h in harmonics], axis=0)
source = source / np.max(np.abs(source))

# typical formants for /a/ (Hz) - used to synthesize
true_formants = [730, 1090, 2440]
bandwidths = [60, 90, 120]

# cascade resonators (all-pole vocal tract)
x = source.copy()
for F, B in zip(true_formants, bandwidths):
    r = np.exp(-np.pi * B / fs)
    theta = 2*np.pi*F / fs
    a = [1.0, -2*r*np.cos(theta), r**2]  # denominator of second-order resonator
    b = [1.0]
    x = signal.lfilter(b, a, x)

synth = x / np.max(np.abs(x)) * 0.95
wavfile.write("synth_vowel_a.wav", fs, (synth * 32767).astype(np.int16))

# ---------------------------
# 2) LPC (Autocorrelation + Levinson-Durbin)
# ---------------------------
def lpc_autocorr(sig, order):
    # autocorrelation (biased/unbiased choice: using full autocorr center)
    r = np.correlate(sig, sig, mode='full')
    mid = len(r)//2
    r = r[mid:mid+order+1]   # r[0..p]
    # Levinson-Durbin
    a = np.zeros(order+1)
    a[0] = 1.0
    e = r[0]
    if e == 0:
        return a, e
    for i in range(1, order+1):
        acc = r[i]
        for j in range(1, i):
            acc += a[j] * r[i - j]
        k = -acc / e
        a_temp = a.copy()
        # update coefficients
        a[1:i] = a_temp[1:i] + k * a_temp[i-1:0:-1]
        a[i] = k
        e *= (1 - k**2)
    return a, e

lpc_order = 14                  # typical choice for 16kHz; tuneable (10-16 often fine)
a_lpc, err_energy = lpc_autocorr(synth, lpc_order)

# ---------------------------
# 3) Compute residual + reconstruct
# ---------------------------
# residual = A(z) * x[n]  (predictor applied to original)
residual = signal.lfilter(a_lpc, [1.0], synth)
# synthesis: filter residual through 1/A(z)
reconstructed = signal.lfilter([1.0], a_lpc, residual)
reconstructed = reconstructed / np.max(np.abs(reconstructed)) * 0.95
wavfile.write("reconstructed_vowel_a.wav", fs, (reconstructed * 32767).astype(np.int16))

# ---------------------------
# 4) Formant estimation from LPC roots
# ---------------------------
roots = np.roots(a_lpc)
# keep roots with positive imaginary part (one of conjugate pair)
roots_pos = [r for r in roots if np.imag(r) > 0.001]
formants = []
for r in roots_pos:
    ang = np.arctan2(np.imag(r), np.real(r))
    freq = ang * fs / (2*np.pi)
    bw = - (fs/(2*np.pi)) * np.log(np.abs(r))
    # heuristics: audible and not too wide
    if 90 < freq < fs/2 and bw < 400:
        formants.append((freq, bw))
formants = sorted(formants, key=lambda x: x[0])
estimated_formants = [f for f,b in formants]

# ---------------------------
# 5) Spectral envelope (LPC freq response)
# ---------------------------
w, h = signal.freqz([1.0], a_lpc, worN=2048, fs=fs)

# ---------------------------
# 6) Plots
# ---------------------------
# show a short slice (first 30 ms) for time-domain comparison
plt.figure(figsize=(9,2.5))
plt.plot(t[:int(0.03*fs)], synth[:int(0.03*fs)])
plt.title("Original synthesized vowel (first 30 ms)")
plt.xlabel("Time (s)"); plt.ylabel("Amplitude"); plt.tight_layout()

plt.figure(figsize=(9,2.5))
plt.plot(t[:int(0.03*fs)], reconstructed[:int(0.03*fs)])
plt.title("Reconstructed from LPC (first 30 ms)")
plt.xlabel("Time (s)"); plt.ylabel("Amplitude"); plt.tight_layout()

plt.figure(figsize=(9,3))
plt.plot(w, 20*np.log10(np.abs(h)))
plt.title("LPC spectral envelope (dB) - formants marked")
plt.xlabel("Frequency (Hz)"); plt.ylabel("Magnitude (dB)")
for f,bw in formants:
    plt.axvline(f, linestyle='--', linewidth=1)
    plt.text(f+10, -5, f"{f:.0f} Hz", rotation=90, verticalalignment='bottom')
plt.xlim(0, 4000)
plt.tight_layout()
plt.show()

# ---------------------------
# 7) Save table comparing true vs estimated formants
# ---------------------------
est_top3 = estimated_formants[:3] + [None]*max(0, 3-len(estimated_formants))
df_comp = pd.DataFrame({
    "Formant": ["F1", "F2", "F3"],
    "True (Hz)": [true_formants[0], true_formants[1], true_formants[2]],
    "Estimated (Hz)": [round(x,1) if x is not None else None for x in est_top3]
})
df_comp.to_csv("formant_comparison.csv", index=False)

# Summary printout
print("LPC order:", lpc_order)
print("First 8 LPC coefficients:", np.round(a_lpc[:8], 4))
print("Estimated formants (Hz) & bandwidths (Hz):")
for f,bw in formants:
    print(f"  {f:.1f} Hz  (BW: {bw:.1f} Hz)")
print("Saved: synth_vowel_a.wav, reconstructed_vowel_a.wav, formant_comparison.csv")



